{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b4cc40ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11bd28cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mount the GCP filesystem onto this VM\n",
    "data_dir = \"/home/parsellsx/tesslcs/\"\n",
    "os.system(f\"gcsfuse --implicit-dirs tess-goddard-lcs {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3b62ff",
   "metadata": {},
   "source": [
    "Let's first try messing around with the Justesen & Albrecht (2021) catalog: can open it up with either Pandas, NumPy, or base Python. I'll try Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c13d7c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that 'skipinitialspace=True' makes it so that the space at the start of the TIC ID in the file doesn't \n",
    "# make pandas interpret it as a NaN. Also, index_col=False makes it not interpret the TIC ID column as indices\n",
    "# and instead treats it as actual data (which it is)\n",
    "justesen = pd.read_table('justesen_albrecht_table2_748ebs.txt',sep=' ',header=None,\n",
    "                     names=['TIC ID','Period','t1','t2','ecosw','d1','d2','Tmag'],index_col=False,skiprows=21,\n",
    "                    skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5578c99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIC ID</th>\n",
       "      <th>Period</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>ecosw</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>Tmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>286191384</td>\n",
       "      <td>3.612096</td>\n",
       "      <td>1572.973792</td>\n",
       "      <td>1574.779530</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.270606</td>\n",
       "      <td>0.265251</td>\n",
       "      <td>9.73600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269852699</td>\n",
       "      <td>5.136474</td>\n",
       "      <td>1653.934920</td>\n",
       "      <td>1651.366865</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.118999</td>\n",
       "      <td>0.099360</td>\n",
       "      <td>10.97370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153709888</td>\n",
       "      <td>4.332752</td>\n",
       "      <td>1438.632392</td>\n",
       "      <td>1440.798759</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.065129</td>\n",
       "      <td>0.064353</td>\n",
       "      <td>11.46520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>307488184</td>\n",
       "      <td>10.066890</td>\n",
       "      <td>1578.299686</td>\n",
       "      <td>1573.359871</td>\n",
       "      <td>0.014594</td>\n",
       "      <td>0.146272</td>\n",
       "      <td>0.014291</td>\n",
       "      <td>10.40570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98478039</td>\n",
       "      <td>0.668014</td>\n",
       "      <td>1491.821919</td>\n",
       "      <td>1491.490477</td>\n",
       "      <td>0.006004</td>\n",
       "      <td>0.035268</td>\n",
       "      <td>0.013835</td>\n",
       "      <td>13.93130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>30287190</td>\n",
       "      <td>3.123596</td>\n",
       "      <td>1602.790072</td>\n",
       "      <td>1601.228367</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.026690</td>\n",
       "      <td>0.010880</td>\n",
       "      <td>11.22510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>407824089</td>\n",
       "      <td>17.945412</td>\n",
       "      <td>1655.350010</td>\n",
       "      <td>1660.097960</td>\n",
       "      <td>0.378821</td>\n",
       "      <td>0.322682</td>\n",
       "      <td>0.153745</td>\n",
       "      <td>8.55980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>320228013</td>\n",
       "      <td>6.804494</td>\n",
       "      <td>1570.688816</td>\n",
       "      <td>1567.623595</td>\n",
       "      <td>0.076529</td>\n",
       "      <td>0.078199</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>10.38770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>178996712</td>\n",
       "      <td>2.982299</td>\n",
       "      <td>1440.462243</td>\n",
       "      <td>1441.953361</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.036636</td>\n",
       "      <td>0.006978</td>\n",
       "      <td>8.58503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>150284425</td>\n",
       "      <td>3.004444</td>\n",
       "      <td>1519.034242</td>\n",
       "      <td>1517.896191</td>\n",
       "      <td>0.187553</td>\n",
       "      <td>0.157974</td>\n",
       "      <td>0.052362</td>\n",
       "      <td>6.02660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>748 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TIC ID     Period           t1           t2     ecosw        d1  \\\n",
       "0    286191384   3.612096  1572.973792  1574.779530  0.000135  0.270606   \n",
       "1    269852699   5.136474  1653.934920  1651.366865  0.000055  0.118999   \n",
       "2    153709888   4.332752  1438.632392  1440.798759  0.000003  0.065129   \n",
       "3    307488184  10.066890  1578.299686  1573.359871  0.014594  0.146272   \n",
       "4     98478039   0.668014  1491.821919  1491.490477  0.006004  0.035268   \n",
       "..         ...        ...          ...          ...       ...       ...   \n",
       "743   30287190   3.123596  1602.790072  1601.228367  0.000047  0.026690   \n",
       "744  407824089  17.945412  1655.350010  1660.097960  0.378821  0.322682   \n",
       "745  320228013   6.804494  1570.688816  1567.623595  0.076529  0.078199   \n",
       "746  178996712   2.982299  1440.462243  1441.953361  0.000017  0.036636   \n",
       "747  150284425   3.004444  1519.034242  1517.896191  0.187553  0.157974   \n",
       "\n",
       "           d2      Tmag  \n",
       "0    0.265251   9.73600  \n",
       "1    0.099360  10.97370  \n",
       "2    0.064353  11.46520  \n",
       "3    0.014291  10.40570  \n",
       "4    0.013835  13.93130  \n",
       "..        ...       ...  \n",
       "743  0.010880  11.22510  \n",
       "744  0.153745   8.55980  \n",
       "745  0.008025  10.38770  \n",
       "746  0.006978   8.58503  \n",
       "747  0.052362   6.02660  \n",
       "\n",
       "[748 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ed7f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       9.73600\n",
       "1      10.97370\n",
       "2      11.46520\n",
       "3      10.40570\n",
       "4      13.93130\n",
       "         ...   \n",
       "743    11.22510\n",
       "744     8.55980\n",
       "745    10.38770\n",
       "746     8.58503\n",
       "747     6.02660\n",
       "Name: Tmag, Length: 748, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justesen['Tmag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37ed6e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    10.4057\n",
       "4    13.9313\n",
       "5    10.1247\n",
       "6    11.8228\n",
       "7     9.1721\n",
       "8    10.8418\n",
       "9     9.2298\n",
       "Name: Tmag, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justesen['Tmag'][3:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1d8a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_mags = np.where(np.logical_and(justesen['Tmag'] > 10, justesen['Tmag'] < 15))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcad6401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n"
     ]
    }
   ],
   "source": [
    "print(good_mags.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3047d56f",
   "metadata": {},
   "source": [
    "OK, so we have 440 objects from this catalog that satisfy our magnitude constraints (10 < m < 15). Let's see how we do with some of the other catalogs. Check out the Villanova TESS EB catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7deb320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tessebs = pd.read_csv('tess_ebs_villanova_tmag_10-15.csv',header=None,names=['TIC ID','Signal ID','BJD0','BJD0_uncert','Period','Period_uncert','Morph','Morph_dist','RA','Dec','Tmag','GLon','GLat','Teff','Log g','Abundance'],index_col=False,skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8d4cac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIC ID</th>\n",
       "      <th>Signal ID</th>\n",
       "      <th>BJD0</th>\n",
       "      <th>BJD0_uncert</th>\n",
       "      <th>Period</th>\n",
       "      <th>Period_uncert</th>\n",
       "      <th>Morph</th>\n",
       "      <th>Morph_dist</th>\n",
       "      <th>RA</th>\n",
       "      <th>Dec</th>\n",
       "      <th>Tmag</th>\n",
       "      <th>GLon</th>\n",
       "      <th>GLat</th>\n",
       "      <th>Teff</th>\n",
       "      <th>Log g</th>\n",
       "      <th>Abundance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58752825</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>239.431751</td>\n",
       "      <td>-41.727175</td>\n",
       "      <td>11.1853</td>\n",
       "      <td>336.194601</td>\n",
       "      <td>8.807419</td>\n",
       "      <td>4140.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233866651</td>\n",
       "      <td>1</td>\n",
       "      <td>1713.9456738359393</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>304.255424</td>\n",
       "      <td>57.797790</td>\n",
       "      <td>10.0026</td>\n",
       "      <td>92.413545</td>\n",
       "      <td>12.287520</td>\n",
       "      <td>6784.0</td>\n",
       "      <td>4.06796</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>438212183</td>\n",
       "      <td>1</td>\n",
       "      <td>1467.521504</td>\n",
       "      <td>0.122983535</td>\n",
       "      <td>-0.443089703</td>\n",
       "      <td>0.000229931</td>\n",
       "      <td>0.798387594</td>\n",
       "      <td>0.044993427</td>\n",
       "      <td>96.428674</td>\n",
       "      <td>14.467879</td>\n",
       "      <td>13.9685</td>\n",
       "      <td>197.157821</td>\n",
       "      <td>0.997073</td>\n",
       "      <td>3457.0</td>\n",
       "      <td>4.97169</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107548305</td>\n",
       "      <td>1</td>\n",
       "      <td>1600.12467</td>\n",
       "      <td>0.000140696</td>\n",
       "      <td>0.048979028</td>\n",
       "      <td>1.16e-07</td>\n",
       "      <td>0.948524226</td>\n",
       "      <td>0.002957082</td>\n",
       "      <td>212.817308</td>\n",
       "      <td>-30.884359</td>\n",
       "      <td>12.4950</td>\n",
       "      <td>322.487545</td>\n",
       "      <td>28.937964</td>\n",
       "      <td>29200.0</td>\n",
       "      <td>5.59962</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369586828</td>\n",
       "      <td>1</td>\n",
       "      <td>1354.160413</td>\n",
       "      <td>0.003828353</td>\n",
       "      <td>0.08201453</td>\n",
       "      <td>2.26e-07</td>\n",
       "      <td>0.89060319</td>\n",
       "      <td>0.000777944</td>\n",
       "      <td>2.517347</td>\n",
       "      <td>-46.015651</td>\n",
       "      <td>11.4755</td>\n",
       "      <td>323.694425</td>\n",
       "      <td>-69.409049</td>\n",
       "      <td>3703.0</td>\n",
       "      <td>4.72854</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>350298314</td>\n",
       "      <td>1</td>\n",
       "      <td>1358.040388</td>\n",
       "      <td>0.000179908</td>\n",
       "      <td>47.71906707</td>\n",
       "      <td>8.21e-05</td>\n",
       "      <td>0.047750384</td>\n",
       "      <td>0.000662931</td>\n",
       "      <td>83.744470</td>\n",
       "      <td>-59.337955</td>\n",
       "      <td>10.4281</td>\n",
       "      <td>267.980778</td>\n",
       "      <td>-32.742174</td>\n",
       "      <td>5468.18</td>\n",
       "      <td>4.59713</td>\n",
       "      <td>-0.213697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>257691369</td>\n",
       "      <td>1</td>\n",
       "      <td>1426.948929</td>\n",
       "      <td>42.91455756</td>\n",
       "      <td>85.85338969</td>\n",
       "      <td>0.000357215</td>\n",
       "      <td>0.220275303</td>\n",
       "      <td>0.002468639</td>\n",
       "      <td>77.860708</td>\n",
       "      <td>-55.310032</td>\n",
       "      <td>10.3467</td>\n",
       "      <td>263.268649</td>\n",
       "      <td>-36.085098</td>\n",
       "      <td>5371.0</td>\n",
       "      <td>4.52776</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>237105551</td>\n",
       "      <td>1</td>\n",
       "      <td>1731.68611</td>\n",
       "      <td>9.334292604</td>\n",
       "      <td>95.72485577</td>\n",
       "      <td>0.58419714</td>\n",
       "      <td>0.504780138</td>\n",
       "      <td>0.009880513</td>\n",
       "      <td>256.110763</td>\n",
       "      <td>79.396820</td>\n",
       "      <td>10.1490</td>\n",
       "      <td>111.825543</td>\n",
       "      <td>31.460067</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>4.16134</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>261261490</td>\n",
       "      <td>1</td>\n",
       "      <td>1617.469023</td>\n",
       "      <td>0.173819711</td>\n",
       "      <td>113.0019633</td>\n",
       "      <td>0.044094578</td>\n",
       "      <td>0.742532257</td>\n",
       "      <td>0.020242752</td>\n",
       "      <td>90.429076</td>\n",
       "      <td>-79.785084</td>\n",
       "      <td>10.3746</td>\n",
       "      <td>291.526483</td>\n",
       "      <td>-28.863854</td>\n",
       "      <td>6456.0</td>\n",
       "      <td>4.26628</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>309792357</td>\n",
       "      <td>1</td>\n",
       "      <td>1675.596477</td>\n",
       "      <td>26.08769008</td>\n",
       "      <td>314.5944807</td>\n",
       "      <td>3.563748289</td>\n",
       "      <td>0.494697348</td>\n",
       "      <td>0.009367111</td>\n",
       "      <td>80.105481</td>\n",
       "      <td>-59.895684</td>\n",
       "      <td>10.0391</td>\n",
       "      <td>268.766098</td>\n",
       "      <td>-34.550541</td>\n",
       "      <td>5180.0</td>\n",
       "      <td>4.49515</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2156 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TIC ID  Signal ID                BJD0  BJD0_uncert        Period  \\\n",
       "0      58752825          1                None         None          None   \n",
       "1     233866651          1  1713.9456738359393         None          None   \n",
       "2     438212183          1         1467.521504  0.122983535  -0.443089703   \n",
       "3     107548305          1          1600.12467  0.000140696   0.048979028   \n",
       "4     369586828          1         1354.160413  0.003828353    0.08201453   \n",
       "...         ...        ...                 ...          ...           ...   \n",
       "2151  350298314          1         1358.040388  0.000179908   47.71906707   \n",
       "2152  257691369          1         1426.948929  42.91455756   85.85338969   \n",
       "2153  237105551          1          1731.68611  9.334292604   95.72485577   \n",
       "2154  261261490          1         1617.469023  0.173819711   113.0019633   \n",
       "2155  309792357          1         1675.596477  26.08769008   314.5944807   \n",
       "\n",
       "     Period_uncert        Morph   Morph_dist          RA        Dec     Tmag  \\\n",
       "0             None         None         None  239.431751 -41.727175  11.1853   \n",
       "1             None         None         None  304.255424  57.797790  10.0026   \n",
       "2      0.000229931  0.798387594  0.044993427   96.428674  14.467879  13.9685   \n",
       "3         1.16e-07  0.948524226  0.002957082  212.817308 -30.884359  12.4950   \n",
       "4         2.26e-07   0.89060319  0.000777944    2.517347 -46.015651  11.4755   \n",
       "...            ...          ...          ...         ...        ...      ...   \n",
       "2151      8.21e-05  0.047750384  0.000662931   83.744470 -59.337955  10.4281   \n",
       "2152   0.000357215  0.220275303  0.002468639   77.860708 -55.310032  10.3467   \n",
       "2153    0.58419714  0.504780138  0.009880513  256.110763  79.396820  10.1490   \n",
       "2154   0.044094578  0.742532257  0.020242752   90.429076 -79.785084  10.3746   \n",
       "2155   3.563748289  0.494697348  0.009367111   80.105481 -59.895684  10.0391   \n",
       "\n",
       "            GLon       GLat     Teff    Log g  Abundance  \n",
       "0     336.194601   8.807419   4140.0     None       None  \n",
       "1      92.413545  12.287520   6784.0  4.06796       None  \n",
       "2     197.157821   0.997073   3457.0  4.97169       None  \n",
       "3     322.487545  28.937964  29200.0  5.59962       None  \n",
       "4     323.694425 -69.409049   3703.0  4.72854       None  \n",
       "...          ...        ...      ...      ...        ...  \n",
       "2151  267.980778 -32.742174  5468.18  4.59713  -0.213697  \n",
       "2152  263.268649 -36.085098   5371.0  4.52776       None  \n",
       "2153  111.825543  31.460067   6100.0  4.16134       None  \n",
       "2154  291.526483 -28.863854   6456.0  4.26628       None  \n",
       "2155  268.766098 -34.550541   5180.0  4.49515       None  \n",
       "\n",
       "[2156 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tessebs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5110b011",
   "metadata": {},
   "source": [
    "All these EBs are in the TIC and they're all in the magnitude range I'm interested in. So between this catalog and the Justesen & Albrecht one above, we have 2596 EBs identified (although there could be overlap - could be as few as 2156). The question is, how many did TESS actually observe/how many do we have light curves for? \n",
    "\n",
    "To figure this out, we should use the lookup tables that are in our Google Cloud buckets. Want to do two things: 1) Get the actual filenames associated with each of our TIC IDs, and 2) Identify any duplicates between catalogs.\n",
    "\n",
    "I've mounted the GCP filesystem on my VM's filesystem, so I should be able to access the lookup files pretty easily from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05b4a1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "# Maybe in order to get rid of duplicates what I should do is just get all the filenames acting as though there's \n",
    "# no duplicates anywhere, then once I have everything, run some function that just identifies duplicates and gets\n",
    "# rid of them. There's probably one pre-built into NumPy or something like that\n",
    "\n",
    "# Lookup tables: filename, RA, dec, TIC ID, sector, camera, CCD, magnitude\n",
    "# How to deal with the fact that there are 26 different lookup tables and I don't really know what sector each \n",
    "# listed EB is in? I could conceivably get the boundaries of each sector in ecliptic coordinates, then convert \n",
    "# each EB's RA/dec to that coordinate system and determine what sector it's in that way, then check the correct\n",
    "# lookup table file to get its filename. Another option would be just looking through every sector, every time, but\n",
    "# that would probably take a really long time. Let's do a test just to see how long it takes for one ID that's in \n",
    "# sector 13 (meaning it would probably be about the average lookup time if there's an equal number of EBs in \n",
    "# sectors 1-13 as in 14-26).\n",
    "lookup14 = pd.read_table('~/tesslcs/sector14lookup.csv',sep=' ',header=None,names=['filename','RA','dec','TIC ID',\n",
    "                                                    'sector','camera','CCD','mag'],index_col=False,skiprows=1)\n",
    "print(lookup14['TIC ID'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "888f60b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         NaN\n",
      "1         NaN\n",
      "2         NaN\n",
      "3         NaN\n",
      "4         NaN\n",
      "           ..\n",
      "4009712   NaN\n",
      "4009713   NaN\n",
      "4009714   NaN\n",
      "4009715   NaN\n",
      "4009716   NaN\n",
      "Name: TIC ID, Length: 4009717, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Why did we get a NaN?\n",
    "print(lookup14['TIC ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be6f43d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          tesslcs_sector_14_104/2_min_cadence_targets/te...\n",
      "1          tesslcs_sector_14_104/2_min_cadence_targets/te...\n",
      "2          tesslcs_sector_14_104/2_min_cadence_targets/te...\n",
      "3          tesslcs_sector_14_104/2_min_cadence_targets/te...\n",
      "4          tesslcs_sector_14_104/2_min_cadence_targets/te...\n",
      "                                 ...                        \n",
      "4009712    tesslcs_sector_14_104/tesslcs_tmag_9_10/tesslc...\n",
      "4009713    tesslcs_sector_14_104/tesslcs_tmag_9_10/tesslc...\n",
      "4009714    tesslcs_sector_14_104/tesslcs_tmag_9_10/tesslc...\n",
      "4009715    tesslcs_sector_14_104/tesslcs_tmag_9_10/tesslc...\n",
      "4009716    tesslcs_sector_14_104/tesslcs_tmag_9_10/tesslc...\n",
      "Name: filename, Length: 4009717, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# OK, so we have all NaN's here. I'm realizing though that I didn't even want the TIC ID, I wanted the filename...\n",
    "print(lookup14['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19a426a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4a0eb447cca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# I bet what's happening is that since the first column (filename) is a string, it then interprets all the rest of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# the columns as strings too. So let me try casting it to an int and see if that solves the issue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookup14\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TIC ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "# ...and interestingly, that works fine. So what's up with the TIC IDs?\n",
    "# I bet what's happening is that since the first column (filename) is a string, it then interprets all the rest of \n",
    "# the columns as strings too. So let me try casting it to an int and see if that solves the issue\n",
    "print(int(lookup14['TIC ID'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75f245ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ooh, that does not seem to be the issue actually. If it's a float NaN then what's the deal? Let's see the type.\n",
    "type(lookup14['TIC ID'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56244381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27693449\n"
     ]
    }
   ],
   "source": [
    "# Duh. I set \"sep\" as \" \" when it's really a CSV - it should be ',' and really I should be using the pd.read_csv()\n",
    "# method as opposed to read_table(). Let's try again:\n",
    "lookup14 = pd.read_csv('~/tesslcs/sector14lookup.csv',header=None,names=['filename','RA','dec','TIC ID',\n",
    "                                                    'sector','camera','CCD','mag'],index_col=False,skiprows=1)\n",
    "print(lookup14['TIC ID'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ee09aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27837522\n"
     ]
    }
   ],
   "source": [
    "print(lookup14['TIC ID'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b388544",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lookup = lookup14['TIC ID'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09148e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "# Awesome - now it works like it should. So let's take this TIC ID and \"search\" through all the lookup files until\n",
    "# we find it, and get the corresponding filename\n",
    "# I see two ways to do this: either read in all the files in advance and keep them in memory (which seems like it\n",
    "# would maybe be memory-intensive enough to crash the VM, but what the hell, I guess I can always add more memory\n",
    "# if I need it) or I can only open and keep in memory the one I'm currently looking through. That would take way \n",
    "# longer, I think, to do this for a lot of objects like I want to do. Let's try it the first way:\n",
    "\n",
    "# We can save memory by only reading in the columns we need - TIC ID and filename\n",
    "lookuplist = [] # List to hold all the dataframes\n",
    "names = ['filename','RA','dec','TIC ID','sector','camera','CCD','mag']\n",
    "for i in range(1,27):\n",
    "    print(i)\n",
    "    lookup = pd.read_csv('~/tesslcs/sector' + str(i) + 'lookup.csv',header=None,names=names,index_col=False,\n",
    "                        skiprows=1,usecols=['filename','TIC ID'])\n",
    "    lookuplist.append(lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5c557",
   "metadata": {},
   "source": [
    "When I tried the above, it made it to sector 10 and then killed the kernel because it was too much data. So it's not going to work like that unless I upgrade the memory on the VM. That's definitely possible but it'd be nice to get it to work without doing that.\n",
    "\n",
    "So I guess the next thing to try would be to actually just read through one lookup table file at a time until we find the TIC ID we're looking for, and then do that same thing for every single TIC ID that we want to get a filename for. \n",
    "\n",
    "If this fails, there are two options that I see right away: 1) give my VM more memory and try again the first way, or 2) actually write some script (which would probably be a little complex) to take the coordinates of a star and transform that into its TESS sector (then I would only need to check one lookup table for each star)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.ctime())\n",
    "test_filename = '' # This will contain the filename of the LC of the TIC ID stored in test_lookup\n",
    "names = ['filename','RA','dec','TIC ID','sector','camera','CCD','mag']\n",
    "test_lookup = str(test_lookup) + '.pkl'\n",
    "for i in range(1,27):\n",
    "    # Now test_lookup is a specific TIC ID that I want to find, and I know it's in sector 14 but for the purposes\n",
    "    # of this test I'm going to pretend I don't know that. Can we find it?\n",
    "    lookuptable = pd.read_csv('~/tesslcs/sector' + str(i) + 'lookup.csv',header=None,names=names,index_col=False,\n",
    "                             skiprows=1,usecols=['TIC ID'],dtype=str)\n",
    "    print(i)\n",
    "    # Two options I can think of: either 1) read in only the TIC ID column and just search that (might be easier \n",
    "    # actually because we can use NumPy-style search tools) and then if the TIC ID is in there, then read in the \n",
    "    # filename column separately, OR 2) read in both columns for every lookup file. My gut is saying 1) will be\n",
    "    # faster\n",
    "    lookuptable['Indexes'] = lookuptable['TIC ID'].str.find(test_lookup) # Make new column - is it ever not -1?\n",
    "    id_inds = np.where(lookuptable['Indexes'] != -1)[0]\n",
    "    if id_inds.size > 0: # I.e., if it finds the TIC ID in the current file\n",
    "        # If the TIC ID is in the current lookup table, then we want to record the filename somewhere\n",
    "        id_index = id_inds[0] # Get line number of this TIC ID\n",
    "        if id_inds.size > 1:\n",
    "            print('More than one LC of this TIC ID in this sector.')\n",
    "        test_filename = pd.read_csv('~/tesslcs/sector' + str(i) + 'lookup.csv',header=None,names=names,\n",
    "                           index_col=False,skiprows=1,usecols=['filename'],dtype=str)['filename'][id_index]\n",
    "        break # We found that TIC ID, so no need to keep looking afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2481de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6547cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc9402",
   "metadata": {},
   "source": [
    "While testing the above, I noticed that if you just search for the actual TIC ID, you might find a different TIC ID in one of the lookup tables that is one digit longer but contains the ID you searched for. That's obviously not desirable, so I recommend searching for the string \"27693449.pkl\" if you're looking for the TIC ID 27693449 (don't just search for the string \"27693449\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d148285",
   "metadata": {},
   "source": [
    "I just now (July 6, 12:50 am) updated my GCP VM to have 4 CPUs and 16 GB RAM, so I'm going to try my original idea again, where I just load in all the lookup files into one big array and then search that for the TIC ID. Let's see if it can handle it this time (before it had only 4 GB). Also I just realized, I don't even need to be reading in the TIC ID column since the TIC ID is included in the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da780c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "lookuplist = [] # List to hold all the dataframes\n",
    "names = ['filename','RA','dec','TIC ID','sector','camera','CCD','mag']\n",
    "for i in range(1,27):\n",
    "    print(i)\n",
    "    lookup = pd.read_csv('~/tesslcs/sector' + str(i) + 'lookup.csv',header=None,names=names,index_col=False,\n",
    "                        skiprows=1,usecols=['filename','TIC ID'],dtype=str)\n",
    "    lookuplist.append(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a07458e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "# Nice - that worked! Only took maybe 3 min or so, which is reasonable\n",
    "# Want to find test_lookup in that big list of dataframes\n",
    "test_string = str(test_lookup) + '.pkl'\n",
    "test_filename = '' # This will store the full filename/filepath to get to the LC for the current TIC ID\n",
    "for i in range(0,26):\n",
    "    print(i)\n",
    "    for j in lookuplist[i]['filename']:\n",
    "        if test_string in j:\n",
    "            test_filename = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6fb5249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tesslcs_sector_16_104/tesslcs_tmag_9_10/tesslc_27693449.pkl'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f183b977",
   "metadata": {},
   "source": [
    "That was unexpected - I put in a TIC ID that I know should be in sector 14, but it returned a filepath to a LC in sector 16. I'm thinking what's happening is that this star is listed in both sector 14 and 16 - let's see if I'm right by rerunning the above but modifying it so it prints out when it finds the star I'm looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4ae200e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "tesslcs_sector_14_104/2_min_cadence_targets/tesslc_27693449.pkl\n",
      "14\n",
      "tesslcs_sector_15_104/tesslcs_tmag_9_10/tesslc_27693449.pkl\n",
      "15\n",
      "tesslcs_sector_16_104/tesslcs_tmag_9_10/tesslc_27693449.pkl\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "test_string = str(test_lookup) + '.pkl'\n",
    "test_filename = '' # This will store the full filename/filepath to get to the LC for the current TIC ID\n",
    "for i in range(0,26):\n",
    "    print(i)\n",
    "    for j in lookuplist[i]['filename']:\n",
    "        if test_string in j:\n",
    "            test_filename = j\n",
    "            print(test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c92d65",
   "metadata": {},
   "source": [
    "OK, looks like I was right about that. So how do we handle the fact that the same star shows up in multiple sectors? I first want to check and see if the lightcurves at each of these 3 filepaths are the same or different - I'm guessing they're different, but if they're the same, then obviously that solves the problem right there because I can just use the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "83086f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightkurve as lk\n",
    "import pickle\n",
    "fp = open('../tesslcs/' + test_filename,'rb')\n",
    "data = pickle.load(fp)\n",
    "fp.close()\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45c0d4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11527.24202197 11517.53789453 11520.07372801 11519.48014372\n",
      " 11517.58868279 11512.91525185 11516.71833628 11515.87992781\n",
      " 11520.7220796  11517.67981281]\n",
      "[24842.00601356 24843.93340531 24837.32042562 24842.38157143\n",
      " 24845.72341041 24848.74637715 24843.88637933 24837.3786363\n",
      " 24850.39537233 24859.10816993]\n",
      "[22889.42036652 22687.42364383 22419.12667487 22243.40924551\n",
      " 22145.96791996 22146.01434627 22175.24243113 22230.55508603\n",
      " 22249.29388284 22265.27186389]\n"
     ]
    }
   ],
   "source": [
    "filename_list = ['tesslcs_sector_14_104/2_min_cadence_targets/tesslc_27693449.pkl',\n",
    "                 'tesslcs_sector_15_104/tesslcs_tmag_9_10/tesslc_27693449.pkl',\n",
    "                 'tesslcs_sector_16_104/tesslcs_tmag_9_10/tesslc_27693449.pkl']\n",
    "for x in filename_list:\n",
    "    fp = open('../tesslcs/' + x,'rb')\n",
    "    data = pickle.load(fp)\n",
    "    fp.close()\n",
    "    print(data[9][:10]) # PCA flux, first 10 measurements - let's see if they're the same for all 3 files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53f6b2b",
   "metadata": {},
   "source": [
    "OK, so we see here that they are not, in fact, the same light curves. Interesting. So I guess what I can do is instead of going through all 26 sectors and picking out the first light curve that matches a given TIC ID, I can pull out _all_ the light curves that match a given TIC ID, and include them all in my training data.\n",
    "\n",
    "What's next? My goal here is to get the filenames for every object in my EB catalogs. So let's do that now - let's start with the two catalogs that I actually have TIC IDs for already (i.e., Justesen & Albrecht and the tessebs Villanova catalog). My goal will be to make a single list or array which just contains a bunch of filenames of light curves that are EBs, and then after filtering out duplicates, just save that list to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d45dbe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TICID_to_filepath(TICID,lookuplist=lookuplist):\n",
    "    # Takes in a TIC ID, searches the GCP bucket for any corresponding filepaths (could be multiple) and returns\n",
    "    # a list (which can be empty) containing all such filepaths.\n",
    "    id_filelist = [] \n",
    "    search_str = '_' + str(TICID) + '.pkl' # This is the string we'll actually look for in lookuplist, our df list\n",
    "    # We include the underscore in search_str to avoid getting other TIC IDs that contain the TIC ID we're looking\n",
    "    # for but have another digit in front of it\n",
    "    for i in range(0,26): # Loop through every dataframe in lookuplist (i.e., every lookup table file)\n",
    "        for j in lookuplist[i]['filename']:\n",
    "            if search_str in j:\n",
    "                id_filelist.append(j)\n",
    "    return id_filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ddef7e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul  6 09:35:01 2021\n",
      "Tue Jul  6 09:35:10 2021\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "TICID_to_filepath(test_lookup)\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a2842",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = [] # This will hold all the filepaths to the light curves corresponding to our catalog TIC IDs\n",
    "# Our two data \"sets\" that we want to iterate through right now are justesen['TIC ID'][good_mags] and \n",
    "# tessebs['TIC ID']. We'll count the number of stars that are found in our GCP bucket LCs and compare that to the\n",
    "# number of stars in the catalog as well as the final size of filelist (which will depend on how many LCs exist\n",
    "# for a single star on average)\n",
    "for i in justesen['TIC ID'][good_mags]:\n",
    "    filelist.extend(TICID_to_filepath(i)) # Get the filepath(s) for this TIC ID, then append to our list of paths\n",
    "for i in tessebs['TIC ID']:\n",
    "    filelist.extend(TICID_to_filepath(i))\n",
    "# Now write filelist to a text file so we have it for later. Remember these are all EBs. Remember also that we\n",
    "# haven't filtered out duplicates yet\n",
    "with open('eb_filepath_list_justesen_tessebs_with_duplicates.txt', 'w') as f:\n",
    "    for item in filelist:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "print(len(filelist))\n",
    "print(\"We put in 2596 TIC IDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "068f9221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.chain at 0x7f51546e9a10>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Want to figure out how to use itertools.chain() instead of list.extend() above because I hear it's faster\n",
    "itertools.chain(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

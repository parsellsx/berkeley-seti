{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b63fc14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import lightkurve\n",
    "import pickle\n",
    "from tess_stars2px import tess_stars2px_function_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e43be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mount the GCP filesystem onto this VM\n",
    "data_dir = \"/home/parsellsx/tesslcs/\"\n",
    "os.system(f\"gcsfuse --implicit-dirs tess-goddard-lcs {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fba768d",
   "metadata": {},
   "source": [
    "## Kepler EBs to TIC IDs and GCP Filepaths\n",
    "In this notebook, I am going to try out what I talked about with Daniel, Ann Marie, and Steve in our weekly meeting on 7/6, which is taking the list of Kepler EBs (from Villanova; keplerebs.villanova.edu) and using their RA/dec to get their TIC IDs with tesspoint, then using their TIC IDs to get the filepaths to their light curves in our GCP storage bucket. Once I have the light curves, I can actually load them in with the loaders in Daniel's SPOcc repository and then start getting features for them and training a model. But that will be in a separate notebook - here I just want to get all the filepaths. \n",
    "\n",
    "Before I get the RA/dec for all 1997 Kepler EBs, I first just want to try out tesspoint on some random EB. I'll take the first EB from the sector 14 lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e90b6398",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup14_path = '~/tesslcs/sector14lookup.csv'\n",
    "lookup14 = pd.read_csv(lookup14_path,header=None,names=['filename','RA','dec','TIC ID','sector','camera','CCD',\n",
    "    'mag'],index_col=False,dtype={'filename':str,'RA':float,'dec':float,'TIC ID':int,'sector':int,'camera':int,\n",
    "    'CCD':int,'mag':float},skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d1dd32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27693449\n"
     ]
    }
   ],
   "source": [
    "# Now I can access the RA and dec of my example star with lookup14['RA'][0] and lookup14['dec'][0]\n",
    "# Let's print the TIC ID of that star so we can tell if tesspoint gets it right later\n",
    "print(lookup14['TIC ID'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed310671",
   "metadata": {},
   "source": [
    "Now I just need to figure out how to actually pass the RA/dec into tesspoint to get the corresponding TIC ID. The Github page (https://github.com/christopherburke/tess-point) has a few examples, but they're not totally clear. It\n",
    "sounds like you can supply just the RA and dec of a star to get various info about it, including TIC ID, RA, dec (even though you just put those in), ecliptic coordinates, sector, camera, CCD, and column and row in pixels. But\n",
    "you have to supply the TIC ID or some kind of numeric identifier to get that info? But it sounds like you don't need to have the TIC ID in advance, which is good. I'm going to try it out with an example below. I'm going to pass in the RA and dec of my example star and see what happens.\n",
    "\n",
    "After reading about it more here (https://github.com/christopherburke/tess-point/blob/master/example_use_tess_stars2py_byfunction.py), I figured out how it works. You can use tesspoint in your Python program by importing the function they show there, so I just added that to my import cell at the top of this file. And then you can feed in one or multiple targets at a time. The \"TIC ID\" that you pass in doesn't actually get used by the program so it doesn't have to really be the TIC ID, it's just used to identify that star in the output because when you feed in a star, it will return not just one, but _every_ sector/camera/CCD that that star appears in. \n",
    "\n",
    "Let me now try passing in the RA/dec of the first 2 stars from the sector 14 lookup table, and see what I get back. For their TIC IDs, I'll just call them 1 and 2, and if this works then when I go to do this for the entire list of 1997 Kepler EBs, I'll use np.linspace or np.arange to generate IDs from 1 through 1997."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a0eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = lookup14['RA'][:2]\n",
    "dec = lookup14['dec'][:2]\n",
    "iden = [0,1]\n",
    "outID, outEclipLong, outEclipLat, outSec, outCam, outCcd, outColPix, outRowPix, scinfo = tess_stars2px_function_entry(iden, ra, dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e154650",
   "metadata": {},
   "source": [
    "Problem: I'm realizing now that tesspoint doesn't actually give you the TIC ID. So I'm going to need some other way to get the filepaths - either get the TIC ID from someplace else, or find a way to use the lookup tables with just RA and dec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e389427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc905e47",
   "metadata": {},
   "source": [
    "OK, this is a bummer but I found a Github repo that seems to be exactly what I want (https://github.com/jradavenport/kic2tic) - the only problem is it has almost no documentation and I question whether it would be accurate. But it has a big CSV file with KIC ID in one column and TIC ID in the other. I'm going to test it out by taking a few (maybe 10) objects from the Kepler catalog and looking them up on SIMBAD to get their TIC IDs, then seeing if they match the one given by the CSV file from this Github repo. Hopefully they do! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947dc9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in that CSV file\n",
    "kic2tic_path = '~/kic2tic/KIC2TIC.csv'\n",
    "k2t = pd.read_csv(kic2tic_path,header=None,names=['KIC ID','TIC ID'],index_col=False,\n",
    "                  dtype={'KIC ID':int,'TIC ID':int},skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78773504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 10 IDs from the file\n",
    "k2t[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7ffcda",
   "metadata": {},
   "source": [
    "Out of the 10 KIC IDs above, 8 of them had the matching TIC ID in SIMBAD, and as for the other 2, SIMBAD couldn't find them based on either the KIC ID or the TIC ID. So I'm feeling a lot more confident now that this CSV file is legit. Let me try another few from somewhere in the middle of the file just to reassure myself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d45a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "k2t['KIC ID'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k2t[85324:85329]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf23ac5",
   "metadata": {},
   "source": [
    "1 of the 5 IDs above wasn't found by SIMBAD, but the other 4 were accurate. I feel good enough to try this out.\n",
    "\n",
    "So the next step is to load in the Kepler EBs Villanova data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d4ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the Villanova Kepler data\n",
    "kepler_path = '~/berkeley-seti/keplerebs_villanova_kmag_10-15.csv'\n",
    "keplerebs = pd.read_csv(kepler_path,header=None,names=['KIC ID','period','period err','bjd0','bjd0 err',\n",
    "    'morphology','RA','dec','gal lon','gal lat','kmag','Teff','SC'],index_col=False,usecols=['KIC ID','period',\n",
    "    'period err','RA','dec','kmag','Teff'],skiprows=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4543d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "keplerebs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04287ca6",
   "metadata": {},
   "source": [
    "And now I want to loop through all 1997 of these EBs and for each one, search for the KIC ID in the k2t dataframe and get the corresponding TIC ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa4a53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we use np.where on a pandas Series?\n",
    "np.where(keplerebs['KIC ID'] == 9408440)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1bbe06",
   "metadata": {},
   "source": [
    "I can! That should make things easier. I have the KIC IDs in the k2t dataframe. As a side note, I contacted Jim Davenport, the man who wrote the kic2tic Github repository that I got this CSV file from. He said it should work fine for my purposes, with the caveat that it might only include the 2-minute cadence targets. I'll see if that's true or not by seeing how many of my 1997 EBs it finds in that list. Let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticids = []\n",
    "not_found_counter = 0 # Will count how many KIC IDs aren't found in the k2t dataframe\n",
    "for kicid in keplerebs['KIC ID']:\n",
    "    inds = np.where(k2t['KIC ID'] == kicid)[0]\n",
    "    if inds.size == 0:\n",
    "        not_found_counter += 1\n",
    "        continue\n",
    "    elif inds.size > 1:\n",
    "        print('More than one line present for KIC ID ' + str(kicid))\n",
    "    ticids.append(k2t['TIC ID'][inds[0]]) # Add the 1st TIC ID to the list (presumably it will be the only TIC ID)\n",
    "print('Number not found: ' + str(not_found_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a338eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e40aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ticids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c23ca1f",
   "metadata": {},
   "source": [
    "Let's go! It worked, and every EB was found! So now I have a list of 1997 TIC IDs, each corresponding to a confirmed eclipsing binary. Now I need to take these TIC IDs and figure out which ones are in sector 14, and for the ones that are, get their filepaths.\n",
    "\n",
    "I'm going to want to loop through the sector 14 lookup table, and for each star in there, see if it's in my \"ticids\" list. If it is, I'll pull out the whole line and store it in a separate dataframe, then save that to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee81e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_14_eb_indices = []\n",
    "for lookup_index, ticid in enumerate(lookup14['TIC ID']):\n",
    "    inds = np.where(ticids == ticid)[0]\n",
    "    if inds.size == 0:\n",
    "        continue\n",
    "    elif inds.size > 1:\n",
    "        print('More than one line present in ticids for TIC ID ' + str(ticid) + ' - this means that 2 KIC IDs point to the same TIC ID in k2t')\n",
    "    sector_14_eb_indices.append(lookup_index) # This time I am just appending the index so I can then make a new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd70ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sector_14_eb_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be74df30",
   "metadata": {},
   "source": [
    "Hmm...why are there none showing up in sector 14? Not what I expected at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff67c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup14['TIC ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7950f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try using tesspoint to get the (TESS) sector of all my Kepler EBs - I'll see what looks most common\n",
    "ra = keplerebs['RA']\n",
    "dec = keplerebs['dec']\n",
    "iden = np.linspace(0,1996,num=1997)\n",
    "outID, outEclipLong, outEclipLat, outSec, outCam, outCcd, outColPix, outRowPix, scinfo = tess_stars2px_function_entry(iden, ra, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9eab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "outSec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c2df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "outID[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(outSec==14)[0].size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38252e8d",
   "metadata": {},
   "source": [
    "It seems based on that like 1885 of my 1997 Kepler EBs actually are in sector 14, which is a relief. But why is that not showing up in what I did? \n",
    "\n",
    "Let me check, since tesspoint says that the very first EB I gave it (the first one in keplerebs, and therefore the first one in the ticids list) is in sector 14, let me check and see if that star's TIC ID shows up anywhere in the lookup table. If not, I'll know there's some sort of problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069d2c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(lookup14['TIC ID'] == ticids[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a834a2",
   "metadata": {},
   "source": [
    "Good news, the first TIC ID in ticids is actually in the lookup table. So it must just be some bug in my code that led to me not getting any sector 14 ones before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20637855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think the problem might be that ticids is a list and not an array. Let me convert it and try again:\n",
    "ticids = np.asarray(ticids)\n",
    "sector_14_eb_indices = []\n",
    "for lookup_index, ticid in enumerate(lookup14['TIC ID']):\n",
    "    inds = np.where(ticids == ticid)[0]\n",
    "    if inds.size == 0:\n",
    "        continue\n",
    "    elif inds.size > 1:\n",
    "        print('More than one line present in ticids for TIC ID ' + str(ticid) + ' - this means that 2 KIC IDs point to the same TIC ID in k2t')\n",
    "    sector_14_eb_indices.append(lookup_index) # This time I am just appending the index so I can then make a new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd81c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sector_14_eb_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73c7303",
   "metadata": {},
   "source": [
    "This seems a lot better, but I'm surprised that there were times where TIC IDs showed up multiple times in ticids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(ticids == 121121622)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(k2t['TIC ID'] == 121121622)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4736b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting, so this TIC ID shows up twice in ticids, indicating two entries in the Kepler KIC ID list map to it\n",
    "# through k2t, but it only shows up once in k2t, which would seem to mean that there are 2 entries of the same\n",
    "# KIC ID (same star) in the Kepler EBs dataset - let's see if that's the case\n",
    "keplerebs['KIC ID'][1125:1135]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efc1c98",
   "metadata": {},
   "source": [
    "I can see that is the case - the KIC ID 4247791 is repeated. I'm guessing this is why the other 7 TIC IDs got flagged for showing up multiple times too (above).\n",
    "\n",
    "One thing I haven't checked yet is whether there are any duplicate TIC IDs in the lookup table, because if there are, that would make two different lookup_index's get appended to the sector_14_eb_indices list when they really only represent one EB (making it look like I have more unique EBs than I really do). But I guess I could filter those out just from the sector_14_eb_indices list by running some kind of duplicate removal function.\n",
    "\n",
    "The duplicates in the ticids list (which, as mentioned in the first paragraph of this cell, above, come from duplicate KIC IDs on the Villanova site) shouldn't be a problem because I'm only appending the lookup_index in the lookup table file, so only one number gets recorded per EB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a5366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove duplicates from sector_14_eb_indices\n",
    "# According to this StackOverflow post, I can use set() to make a list into a set (thereby eliminating duplicates),\n",
    "# then use list() on that set to convert it back into a set. Note however that order is not preserved - but for me\n",
    "# that shouldn't be an issue\n",
    "sector_14_eb_indices_unique = list(set(sector_14_eb_indices))\n",
    "print(len(sector_14_eb_indices_unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b3265c",
   "metadata": {},
   "source": [
    "Nice - there were no duplicates in this list, which means there are no duplicates in the lookup table. So now I have 1809 indices in my lookup14 dataframe, and I can pull those out to get the filenames of these light curves. I think it's just about time for me to record them to a file, then start a new notebook for the actual lightcurve manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c426044",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sector_14_eb_array = lookup14.iloc[sector_14_eb_indices_unique]\n",
    "cleaned_sector_14_eb_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06132278",
   "metadata": {},
   "source": [
    "Awesome - now all I need to do is write this dataframe to a file and I should be good to move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55f7e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I set index=False because I don't care about saving the indices (the numbers in bold in the dataframe above) - \n",
    "# these are just the indices of the relevant EBs within the lookup table, which is now irrelevant info\n",
    "cleaned_sector_14_eb_array.to_csv('cleaned_sector_14_ebs_filepaths.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53b501b",
   "metadata": {},
   "source": [
    "And I now have 1809 EBs with filepath and camera info recorded in the file '~/berkeley-seti/cleaned_sector_14_ebs_filepaths.csv'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
